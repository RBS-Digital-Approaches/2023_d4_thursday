{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7w/8gx4eEIO8QJnDaET04"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Kq3q1oHYC-zE"},"source":["# Re-process bad images\n","If you examine the binarized images, you may well find some where the process we used in the last notebook didn't yield the best results: perhaps Otsu's method didn't yield the best binarization, or perhaps the deskewing routine didn't quite do the trick for a particular page. (I noticed that page 86 fared pretty badly, for instance, and there may be others I'm missing.)\n","\n","This notebook offers an interactive way to tweak the binarization and deskewing methods in order to come up with a better result for any given image. When you have a result that looks better, you can save a new binarized file for  preliminary OCR.\n","\n","If, after checking out the images, you don't see any that need fixing, then you can just skip this altogether. If you do see some that need tweaking, I'd recommend only doing one or two to get a feel for the kinds of adjustments you'd make—in the time we have, there's no need to go for perfect results for all of the images.\n","\n","(**Note:** Because this notebook mostly repackages things we've already done, there are very few comments. There are also some differences here that I introduced to solve little snags along the way. I haven't tested this exhaustively, so some things might not work as expected.)"]},{"cell_type":"code","metadata":{"id":"uRgVSO1N5IrI"},"source":["#Code cell #1\n","#Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_TJWWW-iLikQ"},"source":["#Code cell #2\n","!pip install pytesseract\n","import ipywidgets as widgets\n","from ipywidgets import interact, interact_manual, interactive\n","from PIL import Image, ImageDraw\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pytesseract"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrWhCmS9fjJL"},"source":["#Code cell #3\n","#I'm assuming that you'll be working with the black and white page images\n","#produced by the prior notebook.\n","%cp /gdrive/MyDrive/L-100\\ Digital\\ Approaches\\ to\\ Bibliography\\ \\&\\ Book\\ History-2023/penn_pr3732_t7_1730b.zip /content/penn_pr3732_t7_1730b.zip\n","%cp /gdrive/MyDrive/rbs_digital_approaches_2023/output/penn_pr3732_t7_1730b-bw.zip /content/penn_pr3732_t7_1730b-bw.zip\n","%cd /content/\n","!unzip penn_pr3732_t7_1730b.zip\n","!unzip penn_pr3732_t7_1730b-bw.zip\n","!mv bw/ penn_pr3732_t7_1730b-bw/\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X3fFU2SD7Ore"},"source":["#Code cell #4\n","image_source_directory = '/content/penn_pr3732_t7_1730b/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ihZjgWWc5sJf","cellView":"form"},"source":["#@title 1 - Choose Image to Reprocess\n","#@markdown Run this cell to generate a dropdown menu to select an image that needs to be reprocessed{display: 'form'}\n","image_select = widgets.Dropdown(\n","    description='Choose image',\\\n","    options = ['PR3732_T7_1730b_body00' + i for i in ['01.tif',\n"," '02.tif', '03.tif', '04.tif', '05.tif', '06.tif', '07.tif', '08.tif',\n"," '09.tif', '10.tif', '11.tif', '12.tif', '13.tif', '14.tif', '15.tif',\n"," '16.tif', '17.tif', '18.tif', '19.tif', '20.tif', '21.tif', '22.tif',\n"," '23.tif', '24.tif', '25.tif', '26.tif', '27.tif', '28.tif', '29.tif',\n"," '30.tif', '31.tif', '32.tif', '33.tif', '34.tif', '35.tif', '36.tif',\n"," '37.tif', '38.tif', '39.tif', '40.tif', '41.tif', '42.tif', '43.tif',\n"," '44.tif', '45.tif', '46.tif', '47.tif', '48.tif', '49.tif', '50.tif',\n"," '51.tif', '52.tif', '53.tif', '54.tif', '55.tif', '56.tif', '57.tif',\n"," '58.tif', '59.tif', '60.tif', '61.tif', '62.tif', '63.tif', '64.tif',\n"," '65.tif', '66.tif', '67.tif', '68.tif', '69.tif', '70.tif', '71.tif',\n"," '72.tif', '73.tif', '74.tif', '75.tif', '76.tif', '77.tif', '78.tif',\n"," '79.tif', '80.tif', '81.tif', '82.tif', '83.tif', '84.tif', '85.tif', '86.tif']],\\\n","    value = 'PR3732_T7_1730b_body0001.tif',\n","    style={'description_width': 'initial'})\n","display(image_select)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kz2HNNh27v96"},"source":["#Code cell #5\n","source_image = image_source_directory + image_select.value\n","cv2color_image = cv2.imread(source_image, cv2.IMREAD_COLOR)\n","cv2gray_image = cv2.cvtColor(cv2color_image, cv2.COLOR_BGR2GRAY)\n","cv2_imshow(cv2gray_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"14nCr0eq8Yyq"},"source":["#@title Set values for Gaussian blur {display-mode: \"form\"}\n","#@markdown Try adjusting the value that will be used for blurring in the next cell.\n","\n","#@markdown (You only need to run this cell once—re-running it will simply reset it to the default value. After changing the value of the slider, try re-running the cell below this one.)\n","blur = widgets.IntSlider(min=1, max=31, step=2, value=5, description='Blur')\n","display(blur)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aizkL2j8aUc"},"source":["#Code cell #6\n","cv2blurred_image = cv2.GaussianBlur(cv2gray_image, (blur.value, blur.value), 0)\n","cv2_imshow(cv2blurred_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2 - Cropping\n","If the image is properly cropped, you can skip this step and move on to Step 3 to try adaptive thresholding. If our automatic cropping routine didn;t give us a good result, though, we can try again."],"metadata":{"id":"zBoPtBQQCAlW"}},{"cell_type":"code","source":["#Code cell #7\n","invert_image = cv2.threshold(cv2blurred_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","cv2_imshow(invert_image)"],"metadata":{"id":"g_iZuX38DScH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Set kernel size for dilation {display-mode: \"form\"}\n","\n","#@markdown **Run the code** in this cell to create a set of\n","#@markdown slider widgets for changing the values of the\n","#@markdown \"kernel\" used to dilate the white pixels in the\n","#@markdown image. You can change the height and width of the\n","#@markdown kernel (i.e., the amount of vertical and horizontal\n","#@markdown dilation to be applied) as well as the number of\n","#@markdown iterations (how many times the dilation operation\n","#@markdown will be applied.)\n","\n","#@markdown You only need to run this cell once (re-running\n","#@markdown it will just re-set the values to their defaults).\n","#@markdown You can change the values of the sliders and\n","#@markdown then run Code cell 12 to see the different\n","#@markdown effects that different values have.\n","kernel_width = widgets.IntSlider(description = 'Kernel width', \\\n","                                               min=1, max=25, step=1, value=10)\n","kernel_height = widgets.IntSlider(description='Kernel height', \\\n","                                                 min=1, max=25, step=1, value=20)\n","num_iterations = widgets.IntSlider(description='Iterations', min=1, \\\n","                      max=10, step=1, value=5)\n","display(kernel_width)\n","display(kernel_height)\n","display(num_iterations)"],"metadata":{"id":"YHvjuuYDDxkj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Code cell #8\n","kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_width.value, kernel_height.value))\n","#Create a new image by dilating the prior image using the kernel shape we've set\n","dilate_image = cv2.dilate(invert_image, kernel, iterations=num_iterations.value)\n","cv2_imshow(dilate_image)"],"metadata":{"id":"s7z-Y44iEF_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["h, w = dilate_image.shape[:2]\n","mask = np.zeros((h+2, w+2), np.uint8)\n","\n","# Floodfill from point (0, 0)\n","floodfill_image = dilate_image.copy()\n","cv2.floodFill(floodfill_image, mask, (0,0), 0);\n","# floodfill = cv2.floodFill(invert_image)\n","cv2_imshow(floodfill_image)"],"metadata":{"id":"Znykc4D4X7R1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Set methods for identifying contours\n","#@markdown **Run this cell** to create two dropdowns\n","#@markdown to set the methods OpenCV will use for\n","#@markdown detecting contours.\n","\n","retrieval_select = widgets.Dropdown(\n","    description='Choose contour retrieval method',\\\n","    # options = ['cv2.RETR_' + op for op in ['EXTERNAL', 'LIST', 'CCOMP', 'TREE', 'FLOODFILL']],\\\n","    # options = [cv2.RETR_EXTERNAL, cv2.RETR_LIST, cv2.RETR_CCOMP, cv2.RETR_TREE, cv2.RETR_FLOODFILL],\\\n","    options = ['RETR_EXTERNAL', 'RETR_LIST', 'RETR_CCOMP', 'RETR_TREE', 'RETR_FLOODFILL'],\\\n","    value = 'RETR_EXTERNAL',\\\n","    style={'description_width': 'initial'})\n","contour_approx = widgets.Dropdown(\n","    description = 'Choose contour approximation method',\\\n","    options = ['CHAIN_APPROX_NONE', 'CHAIN_APPROX_SIMPLE', 'CHAIN_APPROX_TC89_L1', 'CHAIN_APPROX_TC89_KCOS'],\\\n","    value = 'CHAIN_APPROX_SIMPLE',\\\n","    style = {'description_width': 'initial'}\n",")\n","display(retrieval_select)\n","display(contour_approx)"],"metadata":{"cellView":"form","id":"oK0dh7KFGnRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Code cell #9\n","#Identify the contours and their hierarchy\n","retrieval_method = {'RETR_EXTERNAL': 0,\n","                    'RETR_LIST': 1,\n","                    'RETR_CCOMP': 2,\n","                    'RETR_TREE': 3,'RETR_FLOODFILL': 4\n","                    }\n","approximation_method = {'CHAIN_APPROX_NONE': 0,\n","                        'CHAIN_APPROX_SIMPLE': 1,\n","                        'CHAIN_APPROX_TC89_L1': 2,\n","                        'CHAIN_APPROX_TC89_KCOS': 3}\n","contours, hierarchy = cv2.findContours(floodfill_image, retrieval_method[retrieval_select.value], approximation_method[contour_approx.value])\n","\n","#These lines are just to visualize what we have. We make a copy of the dilate\n","#image, converting it from binary to color (so we can see colored lines on it),\n","#then draw all of the contours on that new image in green.\n","show_contours = cv2.cvtColor(floodfill_image.copy(), cv2.COLOR_BayerGR2RGB)\n","show_contours = cv2.drawContours(show_contours, contours, -1, (0,255,0), 3)\n","cv2_imshow(show_contours)"],"metadata":{"id":"6JvDs4sgESzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Code cell 14\n","#Get the height and width of the image\n","height = np.shape(floodfill_image)[0]\n","width = np.shape(floodfill_image)[1]\n","\n","#Divide the width by 8\n","eighth = int(width/8)\n","#Find the midpoint on the x-axis\n","midpoint_x = int(width/2)\n","#Create a tuple with the left-most and right-most x-axis for this zone\n","middle_zone = (midpoint_x - eighth, midpoint_x + eighth)\n","\n","#This code is just to display what's going on. We make a copy of the image\n","#that already has our contours drawn in green...\n","show_middle_zone = show_contours.copy()\n","#...then draw two blue lines to show the edges of the middle zone\n","show_middle_zone = cv2.line(show_middle_zone, (middle_zone[0],0),\n","                            (middle_zone[0], height), (255,0,0), 3)\n","show_middle_zone = cv2.line(show_middle_zone, (middle_zone[1],0),\n","                            (middle_zone[1],height), (255,0,0), 3)\n","cv2_imshow(show_middle_zone)"],"metadata":{"id":"cXmKtmxdEVgt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create an empty list\n","middle_zone_contours = []\n","#Iterate through the list of contours\n","for contour in contours :\n","  #https://learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/\n","  M = cv2.moments(contour)\n","  contour_x = int(M[\"m10\"] / M[\"m00\"])\n","  #If the x-axis value of the centroid is in range for teh x-axis values of the\n","  #middle_zone, then add it to the list of middle_zone_contours\n","  if middle_zone[0] <= contour_x <= middle_zone[1] :\n","    middle_zone_contours.append(contour)\n","\n","#This code just shows what we've done\n","show_middle_contours = show_middle_zone.copy()\n","\n","#Iterate through the list of middle_zone_contours, outlining them in purple\n","for middle_contour in middle_zone_contours :\n","  show_middle_contours = cv2.drawContours(show_middle_contours, [middle_contour], -1, (255, 0, 255), 3)\n","cv2_imshow(show_middle_contours)"],"metadata":{"id":"i7tKrA4PFHMe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Code cell 16\n","\n","show_rectangles = cv2.cvtColor(floodfill_image.copy(), cv2.COLOR_BayerGR2BGR)\n","#Put the detected contours back on the image\n","for contour in contours :\n","  #All contours in green\n","  show_rectangles = cv2.drawContours(show_rectangles, contour, -1, (0,255,0), 3)\n","for middle_zone_contour in middle_zone_contours :\n","  #Middle zone contours in purple\n","  show_rectangles = cv2.drawContours(show_rectangles, [middle_zone_contour], -1, (255, 0, 255), 3)\n","\n","rectangles = [cv2.boundingRect(contour) for contour in middle_zone_contours]\n","for rectangle in rectangles :\n","  start_point = (rectangle[0], rectangle[1])\n","  end_point = (rectangle[0] + rectangle[2], rectangle[1] + rectangle[3])\n","  show_rectangles = cv2.rectangle(show_rectangles, start_point, end_point, (0, 0, 255), 3)\n","  show_rectangles = cv2.putText(show_rectangles, str(rectangle[0]) + ',' + str(rectangle[1]),\n","                              (rectangle[0], rectangle[1]),\n","                              cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2)\n","\n","cv2_imshow(show_rectangles)\n","\n","\n"],"metadata":{"id":"BDzN8RKkFIri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Code cell 17\n","#Construct lists of x- and y-axis coordinates for each rectangle\n","leftx_coords = [rectangle[0] for rectangle in rectangles]\n","rightx_coords = [rectangle[0] + rectangle[2] for rectangle in rectangles]\n","topy_coords = [rectangle[1] for rectangle in rectangles]\n","bottomy_coords = [rectangle[1]  + rectangle[3] for rectangle in rectangles]\n","\n","#Get the left-, right-, top-, and bottom-most x- and y-axis values by getting\n","#the minima and maxima of the values in the lists we just made, then\n","#padding them a little bit so that we're not cropping right against the text\n","leftmost = min(leftx_coords) - 100\n","rightmost = max(rightx_coords) + 100\n","topmost = min(topy_coords) - 50\n","bottommost = max(bottomy_coords) + 50\n","\n","#Construct coordinates for the four corners of the imaginary rectangle using the\n","#left-, right-, top-, and bottom-most x- and y-axis values\n","upper_left = (leftmost, topmost)\n","upper_right = (rightmost, topmost)\n","lower_right = (rightmost, bottommost)\n","lower_left = (leftmost, bottommost)"],"metadata":{"id":"CE70F9DhFXiy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Code cell 18\n","#Make a copy of the show_rectangles image with the red rectangles already drawn\n","text_block = show_rectangles.copy()\n","#Draw a rectangle on the image, using the upper_left and lower_right coordinates\n","text_block = cv2.rectangle(text_block, upper_left, lower_right, (255, 255, 0), 3)\n","\n","cv2_imshow(text_block)\n"],"metadata":{"id":"R42AfZcFFbZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Code cell #19\n","text_block_cropped = cv2color_image.copy()\n","y = topmost\n","x = leftmost\n","w = rightmost\n","h = bottommost\n","text_block_cropped = text_block_cropped[y:h, x:w]"],"metadata":{"id":"lsr-raH9nO3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Which image to proceed with?\n","\n","#@markdown **Run this cell** to create a dropdown\n","#@markdown menu to determine how to proceed with\n","#@markdown with attempting to binarize the image\n","\n","binarize_select = widgets.Dropdown(\n","    description='Did you re-crop the image?',\\\n","    options = ['Yes', 'No'],\\\n","    value = 'No',\n","    style={'description_width': 'initial'})\n","display(binarize_select)\n","\n"],"metadata":{"cellView":"form","id":"g7fdISXDnr-D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WMCm0OtY8Cr6"},"source":["## 3 - Try Adaptive Thresholding\n","If you get good results with adaptive thresholding in this step, you can proceed to number 4 (Deskew or Save?)."]},{"cell_type":"code","metadata":{"id":"DxiIuAIT8HRA"},"source":["#Code cell #6\n","if binarize_select.value == 'No' :\n","  rebinarize_image = cv2blurred_image\n","else :\n","  text_block_gray = cv2.cvtColor(text_block_cropped, cv2.COLOR_BGR2GRAY)\n","  text_block_blurred = cv2.GaussianBlur(text_block_gray, (blur.value, blur.value), 0)\n","  rebinarize_image = text_block_blurred\n","cv2_imshow(rebinarize_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"muN0RZqN8m0I"},"source":["#Code cell #8\n","cv2binary_adaptive_image = cv2.adaptiveThreshold(rebinarize_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 30)\n","cv2_imshow(cv2binary_adaptive_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PgTOxaFS9Lgi"},"source":["## 3 - Try Manual Thresholding\n","If you're not liking the results you're getting with adaptive thresholding, you can try manual thresholding, instead. When you've gotten the image looking good to your mind, move on to number 4 (Deskew or Save?)."]},{"cell_type":"code","metadata":{"id":"4eWXOa9o5vuO"},"source":["#Code cell #9\n","if binarize_select.value == 'No' :\n","  pilcolor_image = Image.open(source_image)\n","else :\n","  pilcolor_image = Image.fromarray(text_block_cropped)\n","\n","pilgray_image = pilcolor_image.convert('L')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XTXdTWt80Pu"},"source":["#@title Set a threshold value {display-mode: \"form\"}\n"," #@markdown Run this cell, then use the slider that will appear to adjust the threshold point for our image in the cell below.\n","\n"," #@markdown You only need to run this cell once (re-running it will just set things back to the default value). Try adjusting the slider and then re-running the *next* cell a few times to see the difference that different threshold values make.\n","thresh_value_slider = widgets.IntSlider(\n","    min=0,\n","    max=255,\n","    step=1,\n","    description='Threshold:',\n","    value=150\n",")\n","display(thresh_value_slider)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1BG2Uxa9g6E"},"source":["#Code cell #10\n","thresh = thresh_value_slider.value\n","fn = lambda x : 255 if x > thresh else 0\n","pilbinary_image = pilgray_image.convert('L').point(fn, mode='1')\n","pilbinary_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MavbDTV25NvC"},"source":["## 4 - Deskew or Save?"]},{"cell_type":"code","metadata":{"id":"_nPgyuNT9m-E","cellView":"form"},"source":["#{display-mode: 'form'}\n","#@markdown (Run this cell to create some widgets for this step.)\n","\n","#@markdown Do we need to deskew? If so, which thresholding method produced the better result?\n","\n","#@markdown If you're ready to save the image, select \"No\" and choose which\n","#@markdown thresholded image to save, then skip to the \"Save\" section and\n","#@markdown and proceed to re-OCR.\n","\n","#@markdown If the image needs deskewing, select \"Yes\" and indicate which of\n","#@markdown the thresholded images should be used for deskewing.\n","proceed_to_deskew = widgets.Dropdown(\n","    description='Deskew?',\\\n","    options = ['Yes', 'No'],\\\n","    value = 'Yes',\n","    style = {'description_width': 'initial'}\n","    )\n","thresholded_image = widgets.Dropdown(\n","    description='Binarization Method',\\\n","    options = ['Adaptive Threshold', 'Manual Threshold'],\\\n","    value = 'Adaptive Threshold',\n","    style={'description_width': 'initial'}\n","    )\n","display(proceed_to_deskew)\n","display(thresholded_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPf26omo7PLA"},"source":["### 4.a - Deskew"]},{"cell_type":"code","metadata":{"id":"6DVoWVMO-I-P"},"source":["#Code cell #11\n","if thresholded_image.value == 'Adaptive Threshold' :\n","  image_to_deskew = cv2binary_adaptive_image\n","else :\n","  pass_to_cv2 = np.array(pilbinary_image)\n","  image_to_deskew = pass_to_cv2.astype(np.uint8) * 255\n","thresh = cv2.threshold(image_to_deskew, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzRusw2Y-2_g"},"source":["#@title Set dilation variables { display-mode: \"form\" }\n","#@markdown (Run this cell to create a slider for setting the dilation amount.)\n","kernel_width = widgets.IntSlider(description = 'Kernel width', \\\n","                                               min=10, max=50, step=5, value=30)\n","kernel_height = widgets.IntSlider(description='Kernel height', \\\n","                                                 min=1, max=10, step=1, value=1)\n","num_iterations = widgets.IntSlider(description='Iterations', min=1, \\\n","                      max=10, step=1, value=5)\n","display(kernel_width)\n","display(kernel_height)\n","display(num_iterations)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HE_umtJj-_kO"},"source":["#Code cell #12\n","kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_width.value, kernel_height.value))\n","#We dilate the pixels using the shape defined by kernel, and perform the operation\n","#five times. You could try increasing or decreasing the number of iterations to\n","#see how the output changes.\n","dilate = cv2.dilate(thresh, kernel, iterations=num_iterations.value)\n","cv2_imshow(dilate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTXJ0eRn_LLm"},"source":["#Code cell #13\n","contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EppamiuyAv74"},"source":["#Code cell #14\n","def draw_min_area_rect(cv2minimumarearectangle, base_image) :\n","  draw_min_area_rect = cv2.cvtColor(base_image, cv2.COLOR_BayerGR2RGB)\n","  if isinstance(cv2minimumarearectangle, list) == True :\n","    print(len(cv2minimumarearectangle))\n","    for rect in cv2minimumarearectangle :\n","      min_area_box = cv2.boxPoints(rect)\n","      min_area_box = np.int0(min_area_box)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[0][0], min_area_box[0][1]), \\\n","                                    (min_area_box[1][0], min_area_box[1][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[1][0], min_area_box[1][1]), \\\n","                                    (min_area_box[2][0], min_area_box[2][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[2][0], min_area_box[2][1]), \\\n","                                    (min_area_box[3][0], min_area_box[3][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[3][0], min_area_box[3][1]), \\\n","                                    (min_area_box[0][0], min_area_box[0][1]), (0, 30, 255), 3)\n","      cv2.putText(draw_min_area_rect, str(rect[-1]),\n","                  (int(rect[0][0]) -100, int(rect[0][1])), cv2.FONT_HERSHEY_SIMPLEX,\n","                  1, (0, 30, 255, 255), 3)\n","  else :\n","    min_area_box = cv2.boxPoints(cv2minimumarearectangle)\n","    min_area_box = np.int0(min_area_box)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[0][0], min_area_box[0][1]), \\\n","                                  (min_area_box[1][0], min_area_box[1][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[1][0], min_area_box[1][1]), \\\n","                                  (min_area_box[2][0], min_area_box[2][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[2][0], min_area_box[2][1]), \\\n","                                  (min_area_box[3][0], min_area_box[3][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[3][0], min_area_box[3][1]), \\\n","                                  (min_area_box[0][0], min_area_box[0][1]), (0, 30, 255), 3)\n","    cv2.putText(draw_min_area_rect, str(cv2minimumarearectangle[-1]),\n","                (int(cv2minimumarearectangle[0][0]) -100, int(cv2minimumarearectangle[0][1])),\n","                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 30, 255, 255), 3)\n","\n","  return draw_min_area_rect"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1xu0CamBFDw"},"source":["#@title Angle Calculation Method{display-mode: 'form'}\n","#@markdown (Run this cell to create a widget for use in this step.)\n","\n","#@markdown Do you want to use all minAreaRect angles for deskewing, or\n","#@markdown just the angles from a subset of the largest contours?\n","angle_method = widgets.Dropdown(\n","    description='Select method',\\\n","    options = ['All Rects', 'Selected'],\\\n","    value = 'All Rects',\n","    style={'description_width': 'initial'})\n","num_rects = widgets.IntSlider(description='Top rects', min=1, \\\n","                      max=5, step=1, value=1)\n","\n","display(angle_method)\n","display(num_rects)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOR59uifB0O8"},"source":["#Code cell #15\n","rects = []\n","if angle_method.value == 'All Rects' :\n","  for contour in contours :\n","    minAreaRect = cv2.minAreaRect(contour)\n","    if minAreaRect[1][1] > 60 :\n","      if minAreaRect[-1] not in [-0.0, 0.0, -90.0] :\n","        rects.append(minAreaRect)\n","else :\n","  for contour in sorted_contours[0:num_rects.value] :\n","    minAreaRect = cv2.minAreaRect(contour)\n","    rects.append(minAreaRect)\n","\n","draw_all_rects = draw_min_area_rect(rects, dilate)\n","cv2_imshow(draw_all_rects)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4-f4xKrDJ2T"},"source":["#Code cell #16\n","angle_corrections = []\n","for rect in rects :\n","  points = cv2.boxPoints(rect)\n","  point_tuples = [(point[0], point[1]) for point in points]\n","  sorted_point_tuples = sorted(point_tuples, key = lambda x: x[1])\n","  if -200 < sorted_point_tuples[-1][0] - sorted_point_tuples[-2][0] < 200 :\n","    sorted_point_tuples = [sorted_point_tuples[0], sorted_point_tuples[2], \\\n","                           sorted_point_tuples[1], sorted_point_tuples[3]]\n","  if sorted_point_tuples[-1][0] < sorted_point_tuples[-2][0] :\n","    angle_corrections.append((90 - rect[-1], 1))\n","  else :\n","    angle_corrections.append((rect[-1], -1))\n","  average_angle = np.mean([angle_tuple[0] for angle_tuple in angle_corrections])\n","  plus_or_minus = sum(angle_tuple[1] for angle_tuple in angle_corrections)\n","  if plus_or_minus > 0 :\n","    average_angle = -1.0 * average_angle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNkYS8kiDaH9"},"source":["#Code cell #17\n","average_angle_deskew = image_to_deskew.copy()\n","(h, w) = average_angle_deskew.shape[:2]\n","center = (w // 2, h // 2)\n","# M = cv2.getRotationMatrix2D(center, angle, 1.0)\n","M = cv2.getRotationMatrix2D(center, average_angle, 1.0)\n","deskewed_average_angle = cv2.warpAffine(average_angle_deskew, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n","cv2_imshow(deskewed_average_angle)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QxAa78dZ6J5v"},"source":["### 4.b - Save\n","Save the reprocessed image before re-OCR'ing."]},{"cell_type":"code","metadata":{"id":"xwwFyBUfEBbU"},"source":["#Code cell #18\n","import os\n","output_directory = '/content/penn_pr3732_t7_1730b-bw/'\n","\n","outname = image_select.value.rstrip('.tif') + '-bw.tif'\n","with open(output_directory + outname, 'wb') as new_image :\n","  if proceed_to_deskew.value == 'Yes' :\n","    final_image = Image.fromarray(deskewed_average_angle)\n","\n","  else :\n","    if thresholded_image.value == 'Adaptive Threshold' :\n","      final_image = Image.fromarray(cv2binary_adaptive_image)\n","\n","    if thresholded_image.value == 'Manual Threshold' :\n","      pass_to_cv2 = np.array(pilbinary_image)\n","      intermediate_image = pass_to_cv2.astype(np.uint8) * 255\n","      final_image = Image.fromarray(intermediate_image)\n","\n","  print('Saving ' + image_source_directory + outname)\n","  final_image.save(new_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wwI7f8BFggxF"},"source":["## Move output files back to Google Drive"]},{"cell_type":"code","metadata":{"id":"ToNv6vSzglU7"},"source":["#Code cell #19\n","%cd /content/\n","!zip -r penn_pr3732_t7_1730b-bw.zip penn_pr3732_t7_1730b-bw/\n","!mv penn_pr3732_t7_1730b-bw.zip /gdrive/MyDrive/rbs_digital_approaches_2023/output/penn_pr3732_t7_1730b-bw.zip\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hfL44985fqsc"},"source":["## Clear Colaboratory environment"]},{"cell_type":"code","metadata":{"id":"AYbptmujftlS"},"source":["#Code cell #20\n","%cd /content/\n","!rm -r ./*"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8I-o2DSeL3TB"},"source":["## Moving on to preliminary OCR to get hOCR output\n","The next notebook will have you moving files back into the Colaboratory environment to perform preliminary OCR to get hOCR output and then slice up your page images into line level images. That will be the last step for now!"]}]}