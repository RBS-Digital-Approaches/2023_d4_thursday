{"cells":[{"cell_type":"markdown","metadata":{"id":"wh2j0fLvij2q"},"source":["# Deskewing pages\n","This notebook was designed to introduce one method for automatically deskewing page images in preparation for OCR. For our purposes in this iteration of the class, the details of the process are less important than seeing an example of the ways that images can be computationally changed after initial photography: when you're looking at a digital surrogate, you're seeing an image that has likely been through several processes that attempt to optimize it for the task at hand without a human having to check it at each step of the way.\n","\n","The code in this notebook is drawn from a blog post by Leo Ertuna at [Becoming Human](https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df), but with an adjustment that some experimenting suggests seems to work better for early print."]},{"cell_type":"markdown","metadata":{"id":"xhhbM2leRoE2"},"source":["## 1 - Connect to Google Drive, copy files, and install packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vr2ZLKaBb8Kc"},"outputs":[],"source":["#Code cell #1\n","#Get access to Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kM_B4qhhc4bp"},"outputs":[],"source":["#Code cell #2\n","%cp -r /gdrive/MyDrive/rbs_digital_approaches_2023/output/cropped.zip /content/cropped.zip\n","%cd /content/\n","!unzip cropped.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5kdzNrKcbUL"},"outputs":[],"source":["#Code cell #3\n","#Install IPyWidgets to provide widgets for experimenting with some variables later\n","import ipywidgets as widgets\n","from ipywidgets import interact\n","\n","#Import necessary Python packages for use in our code.\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"aO7EsJLZR5K6"},"source":["## 2 - Opening the image"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"TAxKrLvwC6zw"},"outputs":[],"source":["#@title Select an image\n"," #@markdown **Run this cell** to create a select\n"," #@markdown list widget that allows us to\n"," #@markdown choose an image to process. With\n"," #@markdown an image selected (a default is\n"," #@markdown provided), you can continue\n"," #@markdown working through the code below.\n"," #@markdown FYI: 1730f_p0iv, 1730g_p21, and\n"," #@markdown 1730j_p21 are the best examples\n"," #@markdown of skewed pages in this set.\n","\n"," #@markdown You only need to run this cell once (re-running it will just set things back to the default value). But you can change the image you're working with using the select list in order to see how these processes work given different starting images.\n","\n","import os\n","import glob\n","file_list = sorted([os.path.basename(file) for file in glob.glob('/content/cropped/*.tif')])\n","image_select = widgets.Dropdown(\n","    description='Choose image',\\\n","    options = file_list,\\\n","    value = '1730f_p0iv-cropped.tif',\n","    style={'description_width': 'initial'})\n","display(image_select)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWyifXGpdPDR"},"outputs":[],"source":["#Code cell #5\n","#Identify the skewed image and have OpenCV read it. (This can take a little\n","#while, so give it time to complete.)\n","\n","source_directory = '/content/cropped/'\n","skewed_image = source_directory + image_select.value\n","im = cv2.imread(skewed_image, cv2.IMREAD_COLOR)\n","#Let's see what the image looks like: an excellent image, but a little skewed.\n","cv2_imshow(im)"]},{"cell_type":"markdown","metadata":{"id":"S22E8xx2n42d"},"source":["## 3 - Deskewing the image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLPMgkleaPEW"},"outputs":[],"source":["#Code cell #6\n","#Make a copy of the image\n","new_image = im.copy()\n","#Convert to grayscale\n","gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n","#Apply a Gaussian blur to reduce the effect of any noise in the image\n","blur = cv2.GaussianBlur(gray, (9, 9), 0)\n","#Convert the image to inverted black and white (i.e., white text on a\n","#black background). Note that Ertuna's script uses Otsu's method for\n","#thresholding to black and white.\n","thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","cv2_imshow(thresh)"]},{"cell_type":"markdown","metadata":{"id":"xplCmGRlS4J3"},"source":["### 3.a - Set kernel size for dilation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNEI3nnFnG_7"},"outputs":[],"source":["#@title Set kernel size {display-mode: \"form\"}\n","\n","#@markdown **Run this cell** to create a set of\n","#@markdown slider widgets for changing the values of the\n","#@markdown \"kernel\" used to dilate the white pixels in the\n","#@markdown image. You can change the height and width of the\n","#@markdown kernel (i.e., the amount of vertical and horizontal\n","#@markdown dilation to be applied) as well as the number of\n","#@markdown iterations (how many times the dilation operation\n","#@markdown will be applied.)\n","\n","#@markdown You only need to run this cell once (re-running\n","#@markdown it will just re-set the values to their defaults).\n","#@markdown You can change the values of the sliders and\n","#@markdown then run Code cell 12 to see the different\n","#@markdown effects that different values have.\n","kernel_width = widgets.IntSlider(description = 'Kernel width', \\\n","                                               min=1, max=25, step=1, value=25)\n","kernel_height = widgets.IntSlider(description='Kernel height', \\\n","                                                 min=1, max=25, step=1, value=1)\n","num_iterations = widgets.IntSlider(description='Iterations', min=1, \\\n","                      max=10, step=1, value=3)\n","display(kernel_width)\n","display(kernel_height)\n","display(num_iterations)"]},{"cell_type":"markdown","metadata":{"id":"u7avDI3XfOOJ"},"source":["### 3.b - This is weird, but we've seen this before"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga-SDNWCakMh"},"outputs":[],"source":["#Code cell #7\n","#The kernel variable defines a shape to use for dilating the pixels. If the kernel\n","#is wider than it is tall, the text will tend to run together while more or less\n","#maintaining the vertical dimensions of the text lines.\n","kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_width.value, kernel_height.value))\n","\n","dilate = cv2.dilate(thresh, kernel, iterations=num_iterations.value)\n","cv2_imshow(dilate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEyqVb6ha5VB"},"outputs":[],"source":["#Code cell #8\n","#Determine contours\n","contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","#These next steps are not really part of the deskewing sequence. I've included\n","#them simply so we can see what's happening.\n","show_contours = cv2.cvtColor(dilate, cv2.COLOR_BayerGR2RGB)\n","show_contours = cv2.drawContours(show_contours, contours, -1, (115,255,105), 3)\n","cv2_imshow(show_contours)"]},{"cell_type":"markdown","metadata":{"id":"Uy5WJ4ROiavU"},"source":["### 3.c - Finding the rectangles that fit these contours\n","In the last notebook, we used `boundingRect` to find *straight* bounding rectangles around the text contours. Our problem is slightly different here, since we're interested in lines that *aren't* straight.\n","\n","OpenCV's `minAreaRect` finds the *smallest possible* rectangle that will contain the contour, even if that that smallest possible rectangle is rotated relative to the square edges of the image.\n","\n","This really seems like a case where a picture is worth a thousand words: the green rectangle is produced by `boundingRect` while the red one is produced by `minAreaRect`.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9aZCIgtps07l"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"O6NHzoras9j1"},"source":["`minAreaRect` provides:\n","\n","* the x, y coordinates of the center point of the rectangle;\n","* the width and height of the rectangle; and\n","* the *rotation angle* of the rectangle—which is what we're trying to correct for. (For more on how `minAreaRect` treats this angle, see [this post at *The AI Learner*](https://theailearner.com/tag/cv2-minarearect/). Note, though, that there appears to have been a change in the way OpenCV represents rotation angles that has left lots of people asking for help on Stack Overflow...)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1tU-RbJxJqw"},"outputs":[],"source":["#@title Draw `minAreaRect` boxes {display-mode: \"form\"}\n","\n","#@markdown **Run this cell** to make a function called `draw_min_area_rect`\n","#@markdown available for drawing boxes\n","#@markdown to show `minAreaRect` rectangles. This code isn't\n","#@markdown really part of the procedure, it's just so we can\n","#@markdown see what's happening. It's more confusing than it's\n","#@markdown worth our while to examine in this context, but you can\n","#@markdown look at it if you want to. You were warned.\n","\n","#Code cell #9\n","def draw_min_area_rect(cv2minimumarearectangle, base_image) :\n","  draw_min_area_rect = base_image.copy()\n","  #If we have more than one recttangle...\n","  if isinstance(cv2minimumarearectangle, list) == True :\n","    print(len(cv2minimumarearectangle))\n","    for rect in cv2minimumarearectangle :\n","      #boxPoints gets the coordinates of the four corners of the rotated rectangle,\n","      #which is nice, because figuring them out ourselves would be sort of a drag,\n","      #given the way those rectangles are (of necessity) represented in OpenCV.\n","      min_area_box = cv2.boxPoints(rect)\n","      #Turn corner coordinates into integers\n","      min_area_box = np.int0(min_area_box)\n","      #Draw this rectangle one side at a time, beginning from the upper left\n","      #corner and working clockwise.\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[0][0], min_area_box[0][1]), \\\n","                                    (min_area_box[1][0], min_area_box[1][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[1][0], min_area_box[1][1]), \\\n","                                    (min_area_box[2][0], min_area_box[2][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[2][0], min_area_box[2][1]), \\\n","                                    (min_area_box[3][0], min_area_box[3][1]), (0, 30, 255), 3)\n","      draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[3][0], min_area_box[3][1]), \\\n","                                    (min_area_box[0][0], min_area_box[0][1]), (0, 30, 255), 3)\n","      #Print the angle of rotation in the center of the rectangle\n","      cv2.putText(draw_min_area_rect, str(rect[-1]),\n","                  (int(rect[0][0]) -100, int(rect[0][1])), cv2.FONT_HERSHEY_SIMPLEX,\n","                  1, (0, 30, 255, 255), 3)\n","  else :\n","    min_area_box = cv2.boxPoints(cv2minimumarearectangle)\n","    min_area_box = np.int0(min_area_box)\n","    #This gnarly code again... I should really refactor this into a function,\n","    #because I hate looking at it, and once is bad enough.\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[0][0], min_area_box[0][1]), \\\n","                                  (min_area_box[1][0], min_area_box[1][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[1][0], min_area_box[1][1]), \\\n","                                  (min_area_box[2][0], min_area_box[2][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[2][0], min_area_box[2][1]), \\\n","                                  (min_area_box[3][0], min_area_box[3][1]), (0, 30, 255), 3)\n","    draw_min_area_rect = cv2.line(draw_min_area_rect, (min_area_box[3][0], min_area_box[3][1]), \\\n","                                  (min_area_box[0][0], min_area_box[0][1]), (0, 30, 255), 3)\n","    cv2.putText(draw_min_area_rect, str(cv2minimumarearectangle[-1]),\n","                (int(cv2minimumarearectangle[0][0]) -100, int(cv2minimumarearectangle[0][1])),\n","                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 30, 255, 255), 3)\n","\n","  return draw_min_area_rect"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlqhgCKAdjz3"},"outputs":[],"source":["#Code cell #10\n","#Actually draw the rectangles using the function defined in code cell 9.\n","\n","#Make an image to render\n","draw_rects = show_contours.copy()\n","#An empty list for our minAreaRects\n","rects = []\n","\n","#Iterate through the contours\n","for contour in contours :\n","  #Find the minAreaRect for each contour\n","  minAreaRect = cv2.minAreaRect(contour)\n","  #Ignore minAreaRects with a height of less than 60 pixels: they're probably\n","  #noise.\n","  if (minAreaRect[1][1] > 60) :\n","    #Ignore any text block that appears to be perfectly horizontal--or\n","    #rotated 90 degrees\n","    if minAreaRect[-1] not in [-0.0, 0.0, -90.0, 90.0] :\n","      #If it's passed both of these tests, add it to our list.\n","      rects.append(minAreaRect)\n","\n","#Draw all of the minAreaRects that met our thresholds\n","for rect in rects :\n","  draw_rects = draw_min_area_rect(rect, draw_rects)\n","cv2_imshow(draw_rects)"]},{"cell_type":"markdown","metadata":{"id":"8xqcEPQPE9Yp"},"source":["###3.d - Calculating an average angle to use for deskewing\n","\n","This cell averages the rotation angles of the `minAreaRect`s in order to figure out how much to rotate the image in order to straighten it.\n","\n","In addition to knowing what the angles for the blocks of text are, we do need to keep track of which *direction* each block is skewed. Figuring this out turned out to be less than entiurely straightforward, and I'm not convinced I have the absolute best method here. But this cell works to figure out which corner points derived from the `minAreaRect` represent the bottom corners of the text line and then determines whether the line slopes \"uphill\" or \"downhill\" on the page."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wC1Euf7GBlBM"},"outputs":[],"source":["#Code cell #11\n","#Create an empty list that will hold a series of tuples: the first element will\n","#be the angle, and the second will be either 1 or -1)\n","angle_corrections = []\n","for rect in rects :\n","  #Get the coordinates of the four corners of the minAreaRect\n","  points = cv2.boxPoints(rect)\n","  #Extract those coordinates from the numpy multidimensional array and store\n","  #in a simpler list of tuples. This line is using Python's terse syntax for\n","  #list comprehension:\n","  #https://www.digitalocean.com/community/tutorials/understanding-list-comprehensions-in-python-3\n","  point_tuples = [(point[0], point[1]) for point in points]\n","\n","  #Sort those tuples by their y-coordinate values\n","  sorted_point_tuples = sorted(point_tuples, key = lambda x: x[1])\n","\n","  #If necessary, re-sort the list to have the bottom corners at the end.\n","  #Note: This 200-pixel business is, at this point, an ecxample of SWAG\n","  #(https://en.wikipedia.org/wiki/Scientific_wild-ass_guess)\n","  if -200 < sorted_point_tuples[-1][0] - sorted_point_tuples[-2][0] < 200 :\n","    sorted_point_tuples = [sorted_point_tuples[0], sorted_point_tuples[2], \\\n","                           sorted_point_tuples[1], sorted_point_tuples[3]]\n","\n","  #Determine the slope of the text line\n","  if sorted_point_tuples[-1][0] < sorted_point_tuples[-2][0] :\n","    angle_corrections.append((90 - rect[-1], 1))\n","  else :\n","    angle_corrections.append((rect[-1], -1))\n","\n","#Determine the mean of the angle corrections\n","average_angle = np.mean([angle_tuple[0] for angle_tuple in angle_corrections])\n","\n","#Determine whether the deskew angle should be treated as positive or negative\n","plus_or_minus = sum(angle_tuple[1] for angle_tuple in angle_corrections)\n","#If that sum ends up as a positive number, the deskewing angle\n","#needs to be a negative number\n","if plus_or_minus > 0 :\n","  average_angle = -1.0 * average_angle\n","print(plus_or_minus)\n","print(angle_corrections)\n","print(average_angle)"]},{"cell_type":"markdown","metadata":{"id":"Y7PMczhaqF9b"},"source":["### 3.e - Let's see the deskewed image.\n","We're using information that we calculated by using what is to us a very strange-looking image, and applying it to our original color image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1HoHB64BsSG"},"outputs":[],"source":["#Code cell 12\n","average_angle_deskew = im.copy()\n","(h, w) = average_angle_deskew.shape[:2]\n","center = (w // 2, h // 2)\n","# M = cv2.getRotationMatrix2D(center, angle, 1.0)\n","M = cv2.getRotationMatrix2D(center, average_angle, 1.0)\n","deskewed_average_angle = cv2.warpAffine(average_angle_deskew, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n","cv2_imshow(deskewed_average_angle)"]},{"cell_type":"markdown","metadata":{"id":"bhj9sqWgH2Fk"},"source":["###3.f - Automatically deskewing the image\n","As in the last notebook, we've walked through each step of this process to see how it works. But once we've figured out how to do it, we can write a function to call using a `for` loop."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xNnPSq_FIJ_7"},"outputs":[],"source":["#Code cell 13\n","def deskew_image(image) :\n","  #Convert to gray\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  #Apply Gaussian blur\n","  blur = cv2.GaussianBlur(gray, (9, 9), 0)\n","  #Invert\n","  thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","  #Define the kernel\n","  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n","  #Dilate\n","  dilate = cv2.dilate(thresh, kernel, iterations=5)\n","  #Determine contours\n","  contours, hierarchy = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","  #Decide which contours to keep\n","  rects = []\n","  for contour in contours :\n","    minAreaRect = cv2.minAreaRect(contour)\n","    if minAreaRect[1][1] > 60 :\n","      if minAreaRect[-1] not in [-0.0, 0.0, -90.0, 90] :\n","        rects.append(minAreaRect)\n","  #Average the angle needed to deskew, and determine in which direction\n","  angle_corrections = []\n","  for rect in rects :\n","    #Figure out which of the bottom corners is lowest to determine the slope of\n","    #the rectangle\n","    points = cv2.boxPoints(rect)\n","    point_tuples = [(point[0], point[1]) for point in points]\n","    sorted_point_tuples = sorted(point_tuples, key = lambda x: x[1])\n","    if -200 < sorted_point_tuples[-1][0] - sorted_point_tuples[-2][0] < 200 :\n","      sorted_point_tuples = [sorted_point_tuples[0], sorted_point_tuples[2], \\\n","                            sorted_point_tuples[1], sorted_point_tuples[3]]\n","    #Determine the necessary angle correction, depending on the rectangle's slope\n","    if sorted_point_tuples[-1][0] < sorted_point_tuples[-2][0] :\n","      angle_corrections.append((90 - rect[-1], 1))\n","    else :\n","      angle_corrections.append((rect[-1], -1))\n","  #Find the average angle necessary to correct the skew across the detected segments\n","  average_angle = np.mean([angle_tuple[0] for angle_tuple in angle_corrections])\n","  #Determine whether that angle needs to be positive or negative\n","  plus_or_minus = sum(angle_tuple[1] for angle_tuple in angle_corrections)\n","  if plus_or_minus > 0 :\n","    average_angle = -1.0 * average_angle\n","  #Use averaged angle to rotate the original image around its center\n","  average_angle_deskew = image.copy()\n","  (h, w) = average_angle_deskew.shape[:2]\n","  center = (w // 2, h // 2)\n","  M = cv2.getRotationMatrix2D(center, average_angle, 1.0)\n","  deskewed = cv2.warpAffine(average_angle_deskew, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n","  #Return the deskewed image\n","  return deskewed\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MqFeLXczKTgI"},"outputs":[],"source":["#Code cell 14\n","if not os.path.exists('/content/deskewed/') :\n","  os.makedirs('/content/deskewed/')\n","for file in glob.glob('/content/cropped/*.tif') :\n","  basename = os.path.basename(file)[:-4]\n","  basename += '-deskewed.tif'\n","  original = cv2.imread(file, cv2.IMREAD_COLOR)\n","  deskewed = deskew_image(original)\n","  cv2.imwrite('/content/deskewed/' + basename, deskewed)\n","  print('Saved ' + basename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-7ZNs07LuwP"},"outputs":[],"source":["#Code cell 15\n","%cd /content/\n","!zip -r deskewed.zip deskewed/\n","!mv /content/deskewed.zip /gdrive/MyDrive/rbs_digital_approaches_2023/output/deskewed.zip\n"]},{"cell_type":"markdown","metadata":{"id":"Ex7OkTFozYpP"},"source":["##4 - NOW we can automate optimized binarization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DChPW_hnM6bJ"},"outputs":[],"source":["#Code cell 16\n","text_block = cv2.imread('/content/deskewed/1730g_p21-cropped-deskewed.tif',\n","                        cv2.IMREAD_COLOR)\n","cv2_imshow(text_block)"]},{"cell_type":"markdown","metadata":{"id":"epHbpniMzdDr"},"source":["###4.a - Convert to grayscale"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pHvIHYVzd3e"},"outputs":[],"source":["#Code cell 17\n","text_block_gray = cv2.cvtColor(text_block, cv2.COLOR_BGR2GRAY)\n","cv2_imshow(text_block_gray)"]},{"cell_type":"markdown","metadata":{"id":"rkD4A9imY29h"},"source":["### 4.b - Applying a Gaussian blur"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTBPamUOvPct"},"outputs":[],"source":["#@title Set values for Gaussian blur {display-mode: \"form\"}\n","#@markdown **Run this cell** to create a slider to adjust the\n","#@markdown value of the blur applied to the image.\n","\n","#@markdown (You only need to run this cell once—re-running it will simply reset it to the default value. After changing the value of the slider, try re-running the cell below this one.)\n","blur = widgets.IntSlider(min=1, max=31, step=2, value=5, description='Blur')\n","display(blur)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdlIM0aKzRQV"},"outputs":[],"source":["#Code cell 18\n","text_block_blurred = cv2.GaussianBlur(text_block_gray, (blur.value, blur.value), 0)\n","\n","cv2_imshow(text_block_blurred)"]},{"cell_type":"markdown","metadata":{"id":"fqUncz6da17z"},"source":["### 4.c - Determining an appropriate threshold using Otsu's method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3xzJKfjzUSf"},"outputs":[],"source":["#Code cell 19\n","(T_new, text_block_otsu) = cv2.threshold(text_block_blurred, 0, 255, cv2.THRESH_OTSU)\n","\n","#Output\n","cv2_imshow(text_block_otsu)\n","print('Otsu threshold is: ' + str(T_new))"]},{"cell_type":"markdown","metadata":{"id":"damKGv18RMYT"},"source":["### 4.d - Binarize the images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4MZqb931N9b"},"outputs":[],"source":["#Code cell 20\n","def binarize_image(image) :\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n","  (T, otsu) = cv2.threshold(blurred, 0, 255, cv2.THRESH_OTSU)\n","  return otsu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3tCS9xCRdgg"},"outputs":[],"source":["#Code cell 21\n","if not os.path.exists('/content/bw/') :\n","  os.makedirs('/content/bw/')\n","for file in glob.glob('/content/deskewed/*.tif') :\n","  basename = os.path.basename(file)[:-4]\n","  basename += '-bw.tif'\n","  original = cv2.imread(file, cv2.IMREAD_COLOR)\n","  binarized = binarize_image(original)\n","  cv2.imwrite('/content/bw/' + basename, binarized)\n","  print('Saved ' + basename)"]},{"cell_type":"markdown","metadata":{"id":"dA9wM2-GZ5To"},"source":["###4.e - Let's get three more black and white derivatives for experimental purposes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nduxa6Sfa2mT"},"outputs":[],"source":["#Code cell 22\n","from PIL import Image\n","if not os.path.exists('/content/bw/') :\n","  os.makedirs('/content/bw/')\n","\n","pilcolor_image = Image.open('/content/deskewed/1730f_p21-cropped-deskewed.tif')\n","pilgray_image = pilcolor_image.convert('L')\n","thresh_values = [95, 145, 175]\n","fn = lambda x : 255 if x > thresh else 0\n","for thresh_value in thresh_values :\n","  thresh = thresh_value\n","  pilbinary_image = pilgray_image.convert('L').point(fn, mode='1')\n","  output_filepath = '/content/bw/1730f_p21_manual_'+ str(thresh) + '.tif'\n","  pilbinary_image.save(output_filepath)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsbV9GCuR4S8"},"outputs":[],"source":["#Code cell 23\n","%cd /content/\n","!zip -r bw.zip bw/\n","!mv /content/bw.zip /gdrive/MyDrive/rbs_digital_approaches_2023/output/bw.zip\n"]},{"cell_type":"markdown","metadata":{"id":"O8Pzv3IDgBFk"},"source":["##5 - Possible limitations of Otsu's method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AR2m_cCj9jL"},"outputs":[],"source":["#Code cell #24\n","%cp /gdrive/MyDrive/L-100\\ Digital\\ Approaches\\ to\\ Bibliography\\ \\&\\ Book\\ History-2023/2023_page_images.zip /content/2023_page_images.zip\n","%cd /content/\n","!unzip 2023_page_images.zip\n","foxed = '/content/2023_page_images/st_tz_foxing.jpg'\n","color_foxed = cv2.imread(foxed, cv2.IMREAD_COLOR)\n","cv2_imshow(color_foxed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nXWXaKqvlWv"},"outputs":[],"source":["#Code cell #25\n","gray_foxed = cv2.cvtColor(color_foxed, cv2.COLOR_BGR2GRAY)\n","blurred_foxed = cv2.GaussianBlur(gray_foxed, (5, 5), 0)\n","otsu_foxed = cv2.threshold(blurred_foxed, 0, 255, cv2.THRESH_OTSU)[1]\n","\n","cv2_imshow(otsu_foxed)"]},{"cell_type":"markdown","metadata":{"id":"Wd_k0IZQm83k"},"source":["### 6.e - Applying adaptive thresholding for problematic images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1DBFujh6oXre"},"outputs":[],"source":["#Code cell #26\n","cv2binary_adaptive_image = cv2.adaptiveThreshold(text_block_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 30)\n","cv2_imshow(cv2binary_adaptive_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTQuRUDTwUEZ"},"outputs":[],"source":["#Code cell #27\n","cv2binary_adaptive_image = cv2.adaptiveThreshold(blurred_foxed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 30)\n","cv2_imshow(cv2binary_adaptive_image)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}